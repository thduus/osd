# {{KSL 수어 튜터}}
> {{접근근성과 프라이버시를 최우선으로 한, 초저지연 KSL 입문 수어 학습 튜터}}

- 상태: {{alpha}}
- 라이선스: {{MIT}}
- 주요 기능: {{KSL, 접근성, 오프라인}}
---

## 목차
- [소개](#소개)
- [특징](#특징)
- [설치](#설치)
- [빠른 시작](#빠른-시작)
- [사용법](#사용법)
- [설정](#설정)
- [프로젝트 구조](#프로젝트-구조)
- [로드맵](#로드맵)
- [라이선스](#라이선스)

---

## 소개
{{본 프로젝트는 기존 수어 학습 튜터의 청각 의존성 및 고성능 장비 요구사항이라는 문제를 해결하기 위해 시작되었습니다. 특히, 웹 접근성 지침을 준수하는 시각 중심의 명확한 피드백과 저사양 CPU기반의 경량 인식에 초점을 맞춥니다.}}
- 해결하려는 문제: 기존 수어 튜터의 높은 진입장벽, 시작 정보/청각 의존성, 원본 영상 저장으로 인한 프라이버시 해결 문제
- 대상 사용자: KSL 입문 학습자, 청각 장애 학생 및 교사, 디지털 기기 접근에 제약이 있는 사용자
- 핵심 아이디어: MediaPipe Hands로 손 랜드마크 추출 후, SVM또는 RandomForest 경량 분류기로 실시간 판별. 모든 피드백은 고대비/키보드 전용 흐름으로 제공하여 접근성을 높입니다.

## 특징
- ✅ {{접근성 최우선 UI}}
- ✅ {{프라이버시 및 오프라인 보장}}
- ✅ {{사용자 맞춤형 보정 시스템}}
- ⚙️ {{초경량 CPU기반 인식/자동 성능 완화}}


## 설치

### 최소 요구사항
* Python 3.9+
* Node.js 18+
* 웹캠

```bash
# 1) 저장소 클론
git clone [repo_url] && cd [repo_dir]

# 2) 환경 구성 (택1)
# Python
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt # scikit-learn, mediapipe, pandas 등 설치

# Node
npm i  # 또는 pnpm i / yarn
```

## 빠른 시작

환경 의존성 없이 실행하려면 *Docker**를 사용하는 것이 가장 빠릅니다.

```bash
# 1) CPU 전용 Docker 이미지 빌드
./scripts/setup.sh # 의존성 설치 스크립트 실행
docker build -t ksl-ally-tutor-cpu .

# 2) Docker를 이용한 데모 실행
# /dev/video0는 웹캠 장치 이름입니다. 
docker run -p 3000:3000 --device=/dev/video0 ksl-ally-tutor-cpu

# 브라우저에서 http//localhost:3000 접속
```
## 사용법

###1. 시작 및 캘리브레이션
프로그램 실행 후, 시작 화면에서 **곧비 토글, 폰트 옵션등을 선택할 수 있습니다.
최초 실행 시, 캘리브레이션을 수행하여 사용자의 손 크기와 카메라 각도를 보정합니다.

###2. 학습 모드 (인식)
| 단축키 | 기능 | 설명 |
| :--- | :--- | :---|
| **Space** | 인식 시작/일시 정지 | 수어 동작 인식을 시작하거나 멈춥니다. |
| **R** | 현재 세션 재시작 | 인식 통계 및 연습 세션을 초기화합니다. |
| **Tab** | 포커스 이동 | 모든 버튼가 상호작용 요소는 $\text{Tab}$ 키만으로 접근 가능합니다. |

###3. 연습/퀴즈 모드
랜덤으로 제시된 수어동작을 제한 시간 내에 수행합니다. 
* **정답 시:** 카드 확대, 테두리 두께 변화
* **오답 시:** 오류 메세지

---

## 설정

| 옵션 | 카테고리 | 설명 |
| :--- | :--- | :--- |
| **고대비 모드** | 접근성 | $\text{WCAG}$ 기준 대비 $\text{7:1}$ 이상으로 $\text{UI}$를 전환합니다. |
| **폰트 옵션** | 접근성 | 가독성 높은 $\text{산세리프}$ 또는 $\text{난독증 친화 폰트}$로 토글합니다. |
| **모션 줄이기** | 접근성 | 정답 시 카드 확대 등 과도한 $\text{애니메이션}$ 효과를 최소화합니다. |
| **저사양 모드 토글** | 성능 | $\text{FPS}$가 낮아질 때 자동 전환 로직을 수동으로 켜거나 끕니다. |
| **TTS 활성화** | 청각/자막 | 기본 자막 안내 외에 $\text{TTS}$ (음성) 피드백을 활성화합니다 (선택 사항). |

---

## 프로젝트 구조

KSL-A11y-Tutor/
├── src/               # 핵심 Python 로직 (데이터 처리, 학습 스크립트)
│   ├── features.py    # 랜드마크 -> 특징 (각도, 길이비) 추출 로직
│   └── train.py       # scikit-learn 분류기 (SVM/RF) 학습 로직
├── web/               # 프런트엔드 (React/Vue.js) 코드
│   ├── components/    # 접근성 UI 컴포넌트 (고대비, 폰트 옵션 등)
│   ├── public/        # TFJS 모델 파일 로드 위치
│   └── pages/         # UI 흐름 (시작, 학습, 리포트)
├── models/            # 학습된 모델 저장소 (.pkl 또는 .json/tfjs 형식)
├── data/              # 수집된 키포인트 데이터 (.csv)
├── scripts/           # 자동화 스크립트
│   ├── setup.sh       # 환경 설치 및 의존성 구성
│   ├── collect.sh     # 데이터 수집 (웹캠 프레임 캡처 -> 키포인트 추출)
│   ├── train.sh       # 모델 학습 및 변환 (Python -> TFJS)
│   └── run.sh         # 프로젝트 실행 (Node 또는 Docker run)
└── docs/              # 문서 (README, CONTRIBUTING, LICENSE)

---

## 로드맵

| 단계 | 목표 | 주요 기능 |
| :--- | :--- | :--- |
| **S1 (Alpha)** | 핵심 안정성 및 접근성 기반 확보 | 캘리브레이션/저사양 전환 로직, 고대비 $\text{UI}$ 및 키보드 $\text{Tab}$ 흐름, $\text{MediaPipe}$ 초기 연동. |
| **S2 (Beta)** | 학습 경험 및 확장 기능 추가 | 멀티유저 큐, 교실용 $\text{CSV}$ 리포트, 간단 퀴즈 모드 ($\text{3}$초 제한), 품질 바 $\text{UI}$ 완성. |
| **S3 (Stable)** | 최적화 및 배포 | 모델 경량화 최적화, $\text{Docker}$ 배포 이미지 안정화, $\text{WCAG}$ 최종 검토 및 문서화. |

---

## 라이선스

본 프로젝트의 코드는 **MIT License**를 따릅니다.
단, 학습에 사용되는 $\text{키포인트}$ 데이터셋 및 참조 템플릿은 **CC BY-SA (저작자 표시-동일 조건 변경 허락) License**를 따릅니다.
